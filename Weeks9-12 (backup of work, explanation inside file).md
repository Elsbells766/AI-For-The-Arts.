

### WEEK9-12 
Unfortunatly due to techincal difficulties an hour before submission my weeks 9-12 notenook was saying it was invalid (despite it being fine up until this point). i tired trouble shooting the errors but I was unable to fix them, I prepared this folder with all the writing i completed in the markdowns so it can still be read.

Designing a mini LLM

In designing a Large Language Model (LLM) it was imortant to recap on what they are, as well as how they work, how their design can augment learning, enhance engagement (with cultures and underrepresented groups 

 

My design will highlight these points, aditionally it will include critical analysis on the impact of how it can be used in relation to society. Furthermore, my design will be delivered alongside peer review and reflection. 

 

Prior to engagement with this task, I recapped over notes I had previously taken from lectures and resources from the AI for the Arts (honours program) (University of Glasgow) created and written by Yunhyong Kim. Aditionally, I decided to further search a couple of papers which have been taken on board when thinking about this model. 

 

Extra resources used: 

Chatmon, B. (2020). Males and mental health stigma. American Journal of Men’s Health, 14(4). https://doi.org/10.1177/1557988320949322 

 

Act, A. (2023, August 6). EU AI Act: first regulation on artificial intelligence | Topics | European Parliament. Topics | European Parliament. https://www.europarl.europa.eu/topics/en/article/20230601STO93804/eu-ai-act-first-regulation-on-artificial-intelligence#transparency-requirements-10 

 

var0101. (2023, April 20). Human-Centered Design for AI. Kaggle.com; Kaggle. https://www.kaggle.com/code/var0101/human-centered-design-for-ai 

 

Pooja Chandrashekara. (2024, April 27). Mental Health Chatbot using Llama3 and Langchain. Medium. https://poojachandrashekara.medium.com/introduction-solving-real-world-problems-has-changed-and-is-made-easy-with-transformers-and-42ac9bd4eacc 

 

 

 

Through my work presented below I aim to showcase the information and knowledge I have accumulated through the past 12 weeks. 

 

### Introduction and What is an LLM's: 

 

Through this course I have learned that, LMM’s are AI models that rely on vast amounts of training data (from books, websites, articles, human prompts) this helps them with pattern recognition and ulamitley helps them generate more accurate responses to users prompts and helps then to learn various social ques, us as humans use. They can provide fast text/image responses as well as are able to translate multiple languages and work with code. LLM’s aim to respond as a human would, generating text and in a conversational manor and by asking questions back to the user. They rely on prediction of patterns that they have learned through said training data. LLM’s also rely on neural networks within their structure. The parameters of this help eradicate errors. The way they store knoledge is very different to humans, LLMs store datai n patterns. Examples of where LLM’s can be found are ChatGPT (and other chatbots), T5 by google, llama, and Microsoft copilot (which has been used throughout other weeks of this project) I have explored all of these LLMs in preparation for this project. I found it useful to compare some of them (In the lecture 5 of the AI for arts and humanities course (University of Glasgow)), there was a tool highlighted on github which allowed me to compare different models this was helpful in gaining an undertanding of how they differed from eachother and allowed me to begin reflection regarding what model I may choose to incorprate going forward. 

 

Ethical considerations regarding LLMs are also prominent. Act, (2023) discusses the need to creatre models which are not discriminatory and that LLMs should be cheked by humans in order to ensure they can mitigate harmful outomes. Furthermore, regarding ethics this article discusses the popular generative AI chatGpt 4.0 and how it must comply with transparency requirements and EU copyright laws. This includes, stating that content created within it is AI, designing a model that prevents generating anything illegal as well as by pulishing copyrighted data they used for training. 

 

Furthermore, when considering ethics var0101 (2023) was useful in explaining concepts. They discuss the concept of a human centered design. They highlight how it is important to bring this fctor in as early as possible in the design process as it provides a sense of purpose. Furthermore, discussion about defining what the problem is was helpful, by solidifying what problem/s you are aiming to solve, the more focused on the end goal you will become. The resource then allowed me to relfect on my idea by asking questions, questions included "Would people generally agree that what you are trying to achieve is a good outcome?" and "Is the task that you are using AI for one that people would find boring, repetitive or otherwise difficult to concentrate on?" I took both of these questions on board when thinking of my design. The resource also reminded me to be especially careful of potential risks and harms that may come from my LLM, a futher consideration I hve displayed In my reflection section. 

 

I feel when designing It is important to create some ting I would use personally and feel would make a difference on society. Hence, I will be highlight how LLM’s can be used to advance care in information regarding mental health. I would like to preface the design of this model does not aim to replace therapy/ professional care but simply aims to act as a further resource for individuals to learn more about various mental health issues. AI can be used to provide 24/7 support and aid in answering questions to support users who are going through a tough time (or are just curious!). 

 

### MY LLM: 

 

I am proposing an LLM that will be able to provide fast and nurturing responses to questions users have regarding the mental the health topics such as anxiety and stress. this LLM could be used as a teaching tool as well as for perosnal use and will focus on letting individuals reflect upon their personal situations, by programming the model to ask reflective questions. Furthermore, it will provide resources to professional places to seek help if prompts from the user become alarming (or the user asks for them). My LLM should consider the types of tone and phrases used for responses. (Many individuals who are concerned over health issues in general and may be anxious) By integrating empathetic Reponses into this model, it will be able to accommodate for all users. In order to run, my LLM will need to use vast amounts of training data form health websites and organisations to accumulate facts and knowledge on these different topics. When looking at the resource from Pooja Chandrashekara (2024) they displayed a menthal health LLM, the has test dataset 

(https://www.who.int/news-room/questions-and-answers/item/stress, https://www.who.int/news-room/fact-sheets/detail/mental-disorders) (which they used as training data). After consoldationg my idea I found it intresting to go through and try to grasp the process they were using in order to create their model. In the furture  

 

### How it could augment learning and enhance inclusion: 

Regarding the learning aspect, this design focuses on self reflection (the user will both learn about themselves and mindfulness). The LLM will be able to generate questions and further prompts that push users to think outside the box as well as be able to teach basic coping mechanisms (breathing techniques, meditation, journaling etc). It will also be able to generate long chunck of informational text on topics which could aid in just learning about the topic. Furthermore, when discussing inclusion, it is important to understand that not everyone has someone to help them reflect to their feelings and converse with. In addition, not everyone likes sharing how they are feeling with others, this LLM provides a space for users to be truthful and learn (as mentioned if prompts from the user were getting too worrying, direction to professional care would be generated as a saftey precaution). 

 

### Mock up converstaions between users and LLM I created: 

 

I decided it could be an intresting approch to write upsome expample interactions I expect to see within my LLM:  

 

User: Hello, I'm not feeling so good today, can you help by giving me information on anxiety? 

 

LLM: oh, I'm sorry to hear that. Anything in particular got you feeling down? (inserts information regarding anxiety) 

 

User: I've just had a busy week, thank you for the information.  

 

LLM: Don't worry at all, I'm always here to chat to.  

 

##### This highlights the empathetic tone of the LLM, making the user feel comfertable.  

 

User: I need help. 

LLM: What can I do for you, are you okay?  

 

User: Not really, I think I need to see someone about this.  

 

LLM. Thanks for telling me, that's really, here are a list of numbers and link (insert numbers and links)  

 

##### This highlights the LLMs ability to pull in external recourses when needed (it would also do this when the LLM feels the prompts of the user are getting alarming.  

 

User: Hello, I was wondering if you would be able to give me a step by step guide on how to journal my feelings. I've been feeling stressed.  

 

LLM: Hey, firstly I'm sorry you're feeling stressed and secondly of course I can explain how to journal your feelings. This is such a positive step your taking ! (inserts how to journal feelings). You could also think about trying to relax in different ways such as running a hot bath (etc) 

 

##### This further highlights that providing empathetic responses for basic mindfulness practices would be beneficial While the LLM will be trained to have knowledge about deeper topics, it will not be allowed to give anything other than mindfulness advice as its aim is not to replace therapy or professional care, just for support and knowledge.  

 

#### When asking my peers what they thought of these example converstations, they agreed that the empathetic tone was needed when discussing this topic, aditionally they liked the varying range of senarios. The only feedback they gave me was, going forward that I should select specific datasets to base my LLM from, they highlighted having the data that will be used will elevate my design plan. 

 

### Critical analysis of my LLM (and solutions): 

 

Due to the topic, mental health can accumulate a lot of sensitive information. To aid in mitigating these concerns (regarding privacy and to consider ethical concerns), using LLMs such as llama or ollama would be suitable. Llama is metas lagest language model and ollama is an open source app that can generate LLMs on local devices (Pooja Chandrashekara, 2024). This would mean users could keep track of their data as it would be on their local devices. This would be a better fit as opposed to something such as ChatGPT 4, where users are unsure of where their data is going. Furthermore, there may be issues regarding, misinformation being spread due to accidental biases in training data. This is something that is difficult to fully get rid of, however providing a warning of sorts could be a good way to remind users that they should speak to a professional if unsure of a response (as well as complying with EU guidelines (Act, 2023)) My LLM could have both social and cultural benefits too. It could help reduce stigma around mental health, particularly for men as men's mental health often attracts criticism due to stigma (Chatmon, 2020). A well as this it could help voice basic coping mechanisms and provide information for those who are just simply curious about the topic. This would mean more individuals in society would be educated. It could also aid as an assistent in learning tools in schools. Furthermore, it could direct those who need further help to professionals, meaning people who are struggling would have a higher chance of being taken care of properly. Finally, it could also be used as a way to promote the use of safe and ethical use of AI on the whole  

 

### Peer group review 

 

Upon discussion with my lab group, we disscued our different approaches to this task and shared our different ideas for LLM applications. Through this, we unanimously agreed upon the importance of LLM’s in various areas such as cultural heritage, which members of my group decided to revolve there models around. However, because my topic has the potential to carry more sensitive data, I could also acknowledge potential risks (regarding privacy and ethical concerns). Peer feedback was useful in consolidating my idea as it allowed for different perspectives. Reffering back to the paper resource created by var0101 (2023), the way I chose to propose my idea to my peers as recommended. I wrote a couple of sentences explaining my aims for the design and what I hope for it to achieve. Furthermore, my peers gave positive feedback on my LLM model using llama or ollama for data privacy reasons.  

 

proposal given to peers: 

 

This LLM aims to act as a learning resource for those who want to practice mindfulness or learn about mental health. This LLM is not able to give extensive advice on perosnal mental health issues (if asked), it will direct users to in person professionals (installation of saftey measures). I aim for this learning reasource to be helpful in educating indiviudals on mental health and further breaking stigmas around it (especially regardging mens mental health). Not everyone has accsessd to information on these topics and I feel society would benefit if more people were educated on topics. 

 

## Final reflection on this portfolio: 

Upon reflection of all the tasks I have completed, they have all been useful in fulfilling the aims I had when embarking on this portfolio. Weeks 1-2 helped give me a solid background of context on GitHub, python and how copilot could be used in helping understand code. When referring back to my aims, I have now successfully created an organised portfolio to display my work. Furthermore, I am now able to understand and use basic functions of GitHub. When reflecting upon python code and understanding basic coding concepts, this was the area I was least confident about due to my lack of experience with code. However, due to the help of Copilot I was able to complete these tasks and fulfil these aims. This project has taught me a lot about how copilot can be used in a way to enhance learning, its responses were clear and helpful. Additionally, when I struggled to understand certain aspects, I was able to further interrogate copilot until I understood. These tasks have aided in my understanding an ability to read code and identify errors as well as given me the tools to critically analyse work I have done. Furthermore, discussions with peers was useful, comparing and explaining to one another what we had learnt helped to further develop my knowledge. In wees 6-8 I was able to. Finally, the last task I completed was useful and interesting. I enjoyed the creative freedom we were allowed when completing this task as well as how it allowed for even further consolidation of literature and resources I read. Overall, while some elements of this portfolio I found challenging, it has ultimately given me a deeper understanding of GitHub, Python code, code spaces, Copilot and LLMs. As well as provided me with skills that can be transferred in projects in the future.  

 

 

 

 
